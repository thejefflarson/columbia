<html>
  <head>
    <title>Class Nine | Columbia GIS</title>
    <link rel="stylesheet" href="../stylesheets/reset.css">
    <link rel="stylesheet" href="../stylesheets/tachyons.min.css">
  </head>
  <body class="sans-serif center mv4 pa3 bg-washed-yellow dark-gray f5 lh-copy w-70-l">
    <h2 class="fw1 f3 mv3 bb ttu lh-title tracked">Update</h2>
    <p class="measure-wide pb2">No class next week have a good Thanksgiving! Also, no more homework to allow you time to do your final projects, which are due on Dec. 9th, as is any homework you're still working on.</p>
    <h2 class="fw1 f3 mv3 bb ttu lh-title tracked">Raster Classification</h2>
    <p class="measure-wide pb2">Let's teach our computers to see patterns in raster data using a type of statistical model called a Logistic regression.</p>
    <p class="measure-wide pb2">First though, we'll use ogr2ogr, gdaltranslate, and the rio command line tools to get our data into shape.</p>
    <pre class="f4 code fw3">
#! /bin/bash

ogr2ogr brooklyn.shp tl_2016_us_county.shp -sql "select * from tl_2016_us_county where COUNTYFP = '047' and STATEFP = '36'" -t_srs 'EPSG:32618'

ogr2ogr manhattan.shp tl_2016_us_county.shp -sql "select * from tl_2016_us_county where COUNTYFP = '061' and STATEFP = '36'" -t_srs 'EPSG:32618'

ogr2ogr parks.json tl_2016_36_arealm.shp -f GeoJSON -sql "select * from tl_2016_36_arealm where MTFCC like 'K218%'" -t_srs 'EPSG:32618'

# from https://github.com/dwtkns/gdal-cheat-sheet
function ogr_extent() {
    if [ -z "$1" ]; then
        echo "Missing arguments. Syntax:"
        echo "  ogr_extent <input_vector>"
        return
    fi
    EXTENT=$(ogrinfo -al -so $1 |\
        grep Extent |\
        sed 's/Extent: //g' |\
        sed 's/(//g' |\
        sed 's/)//g' |\
        sed 's/ - /, /g')
    EXTENT=`echo $EXTENT | awk -F ',' '{print $1 " " $4 " " $3 " " $2}'`
    echo -n "$EXTENT"
}

for i in $( ls *.TIF ); do
    gdal_translate $i brooklyn-$i -projwin $(ogr_extent brooklyn.shp)
    gdal_translate $i manhattan-$i -projwin $(ogr_extent manhattan.shp)
done

rio rasterize parks.tif --like brooklyn-B1.TIF < parks.json</pre>
    <h2 class="fw1 f3 mv3 bb ttu lh-title tracked">Building the Model and Testing It</h2>
    <p class="measure-wide pb2">
      We'll use <a href="http://statsmodels.sourceforge.net/">statsmodels</a> to
      train the model using logistic regression.
    </p>
    <pre class="f4 code fw3">
import statsmodels.api as sm
import rasterio as rio
import numpy as np


def correct(img):
    mask = np.logical_and(img > 0, img < 65535)
    top = np.percentile(img[mask], 99.9)
    bottom = np.percentile(img[mask], 0.01)
    scaled = (img - bottom) / (top - bottom) * 65535
    return np.clip(scaled, 0, 65535).astype(np.float64)

X = []
for i in range(1, 8):
    with rio.open('nyc/brooklyn-B%s.TIF' % i) as source:
        band = source.read(1).flatten()
        band = correct(band) / 65535
        X.append(band)

with rio.open('nyc/parks.tif') as parks:
    Y = parks.read(1).flatten().astype(np.float64)

X = np.array(X).transpose()
X = sm.tools.tools.add_constant(X)

model = sm.Logit(Y, X)
res = model.fit()
print(res.summary())

X = []
for i in range(1, 8):
    with rio.open('nyc/manhattan-B%s.tif' % i) as source:
        band = source.read(1)
        shape = band.shape
        band = band.flatten()
        band = correct(band) / 65535
        X.append(band)
        meta = source.meta

X = np.array(X).transpose()
X = sm.tools.tools.add_constant(X)
Y = model.predict(res.params, exog=X)
# convert to probability http://www.ats.ucla.edu/stat/mult_pkg/faq/general/odds_ratio.htm
Y = np.exp(Y) / (1 + np.exp(Y))
meta['count'] = 1
meta['dtype'] = 'float64'
with rio.open('nyc/manhattan-parks.tif', 'w', **meta) as out:
    out.write(Y.reshape(shape), indexes=1)
</pre>
  </body>
</html>
